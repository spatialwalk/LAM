#!/usr/bin/env python3
"""
è½¬æ¢VHAP_trackè¾“å‡ºä¸ºLAMå…¼å®¹çš„é©±åŠ¨æ–‡ä»¶æ ¼å¼

æ–°å¢åŠŸèƒ½ï¼š
- è‡ªåŠ¨å¤„ç†è§†é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ.mp4/.mov/.avi/.mkvç­‰æ ¼å¼ï¼‰
- è‡ªåŠ¨æå–éŸ³é¢‘æ–‡ä»¶
- ç”Ÿæˆå®Œå…¨ç¬¦åˆmulti_view_image_generation.pyè¦æ±‚çš„è¾“å…¥æ•°æ®é…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
1. è®¾ç½®vhap_dirä¸ºVHAPè¾“å‡ºç›®å½•
2. è®¾ç½®output_dirä¸ºLAMçš„assets/sample_motion/exportç›®å½•
3. è®¾ç½®source_video_pathä¸ºåŸå§‹è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
4. è¿è¡Œè„šæœ¬ï¼Œæ‰€æœ‰å¿…éœ€æ–‡ä»¶å°†è‡ªåŠ¨ç”Ÿæˆ
"""

import os
import numpy as np
import json
import shutil
import argparse
from pathlib import Path

def get_video_info(video_path):
    """
    è·å–è§†é¢‘æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: åŒ…å«è§†é¢‘ä¿¡æ¯çš„å­—å…¸
    """
    try:
        from moviepy.editor import VideoFileClip
        clip = VideoFileClip(video_path)
        
        info = {
            'duration': clip.duration,
            'fps': clip.fps,
            'size': clip.size,
            'has_audio': clip.audio is not None,
            'format': os.path.splitext(video_path)[1].lower()
        }
        
        clip.close()
        return info
    except Exception as e:
        print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None

def convert_video_format(input_video_path, output_video_path, target_fps=30):
    """
    è½¬æ¢è§†é¢‘æ ¼å¼å¹¶æå–éŸ³é¢‘
    
    Args:
        input_video_path: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_video_path: è¾“å‡ºMP4æ–‡ä»¶è·¯å¾„
        target_fps: ç›®æ ‡å¸§ç‡
    
    Returns:
        tuple: (video_success, audio_path) 
    """
    try:
        from moviepy.editor import VideoFileClip
        print(f"ğŸ¬ æ­£åœ¨è½¬æ¢è§†é¢‘æ ¼å¼: {input_video_path} -> {output_video_path}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_video_path), exist_ok=True)
        
        # åŠ è½½è§†é¢‘
        clip = VideoFileClip(input_video_path)
        print(f"   åŸå§‹è§†é¢‘ä¿¡æ¯: {clip.duration:.2f}ç§’, {clip.fps:.2f}FPS, {clip.size[0]}x{clip.size[1]}")
        
        # è½¬æ¢ä¸ºç›®æ ‡å¸§ç‡çš„MP4ï¼Œä¿æŒåŸå§‹åˆ†è¾¨ç‡æ¯”ä¾‹
        if clip.size[1] > 720:  # å¦‚æœé«˜åº¦è¶…è¿‡720pï¼Œè¿›è¡Œç¼©æ”¾
            clip_resized = clip.resize(height=720)
            print(f"   è°ƒæ•´åˆ†è¾¨ç‡ä¸º: {clip_resized.size[0]}x{clip_resized.size[1]}")
        else:
            clip_resized = clip
        
        # å†™å…¥è§†é¢‘æ–‡ä»¶
        clip_resized.write_videofile(
            output_video_path, 
            codec='libx264', 
            fps=target_fps,
            audio_codec='aac',
            verbose=False,  # å‡å°‘è¾“å‡ºä¿¡æ¯
            logger=None
        )
        
        # å•ç‹¬æå–éŸ³é¢‘ï¼Œç¡®ä¿é«˜è´¨é‡
        audio_path = output_video_path.replace('.mp4', '.wav')
        audio_success = False
        
        if clip.audio is not None:
            try:
                print(f"ğŸµ æ­£åœ¨æå–éŸ³é¢‘...")
                clip.audio.write_audiofile(
                    audio_path,
                    verbose=False,
                    logger=None
                )
                if os.path.exists(audio_path) and os.path.getsize(audio_path) > 0:
                    audio_size = os.path.getsize(audio_path) / 1024  # KB
                    print(f"âœ… éŸ³é¢‘æå–æˆåŠŸ: {audio_path} ({audio_size:.1f} KB)")
                    audio_success = True
                else:
                    print("âš ï¸  éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥æˆ–ä¸ºç©º")
                    audio_path = None
            except Exception as audio_error:
                print(f"âš ï¸  éŸ³é¢‘æå–å¤±è´¥: {str(audio_error)}")
                audio_path = None
        else:
            print("âš ï¸  æºè§†é¢‘æ²¡æœ‰éŸ³é¢‘è½¨é“")
            audio_path = None
        
        # æ¸…ç†èµ„æº
        if clip.audio:
            clip.audio.close()
        clip.close()
        if clip_resized != clip:
            clip_resized.close()
        
        video_size = os.path.getsize(output_video_path) / 1024 / 1024  # MB
        print(f"âœ… è§†é¢‘è½¬æ¢æˆåŠŸ: {output_video_path} ({video_size:.1f} MB)")
        return True, audio_path
        
    except Exception as e:
        print(f"âŒ è§†é¢‘è½¬æ¢å¤±è´¥: {str(e)}")
        return False, None

def process_video_file(source_video_path, output_dir, target_name):
    """
    å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œå¤åˆ¶/è½¬æ¢è§†é¢‘å¹¶æå–éŸ³é¢‘
    
    Args:
        source_video_path: æºè§†é¢‘æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        target_name: ç›®æ ‡æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        
    Returns:
        bool: å¤„ç†æ˜¯å¦æˆåŠŸ
    """
    if not source_video_path or not os.path.exists(source_video_path):
        print(f"âš ï¸  è·³è¿‡è§†é¢‘å¤„ç†ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ {source_video_path}")
        return False
    
    target_mp4 = output_dir / f'{target_name}.mp4'
    target_audio = output_dir / f'{target_name}.wav'
    
    # è·å–å¹¶æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
    print(f"\nğŸ“¹ åˆ†æè§†é¢‘æ–‡ä»¶: {source_video_path}")
    video_info = get_video_info(source_video_path)
    if video_info:
        print(f"   æ ¼å¼: {video_info['format']}")
        print(f"   æ—¶é•¿: {video_info['duration']:.2f}ç§’")
        print(f"   å¸§ç‡: {video_info['fps']:.2f} FPS")
        print(f"   åˆ†è¾¨ç‡: {video_info['size'][0]}x{video_info['size'][1]}")
        print(f"   åŒ…å«éŸ³é¢‘: {'æ˜¯' if video_info['has_audio'] else 'å¦'}")
    
    # è·å–æºæ–‡ä»¶æ‰©å±•å
    source_ext = os.path.splitext(source_video_path)[1].lower()
    supported_formats = ['.mp4', '.mov', '.avi', '.mkv', '.wmv', '.flv', '.webm']
    
    if source_ext not in supported_formats:
        print(f"âš ï¸  è­¦å‘Š: ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼ {source_ext}")
        print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(supported_formats)}")
        return False
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢
    need_convert = True
    if source_ext == '.mp4':
        # å¦‚æœæ˜¯MP4æ ¼å¼ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥å¤åˆ¶
        print(f"ğŸ“‹ å¤åˆ¶MP4æ–‡ä»¶: {source_video_path} -> {target_mp4}")
        shutil.copy2(source_video_path, target_mp4)
        need_convert = False
        
        # å°è¯•æå–éŸ³é¢‘
        try:
            from moviepy.editor import VideoFileClip
            clip = VideoFileClip(source_video_path)
            if clip.audio is not None:
                print(f"ğŸµ æå–éŸ³é¢‘æ–‡ä»¶...")
                clip.audio.write_audiofile(str(target_audio), verbose=False, logger=None)
                print(f"âœ… éŸ³é¢‘æå–æˆåŠŸ: {target_audio}")
            else:
                print("âš ï¸  æºè§†é¢‘æ²¡æœ‰éŸ³é¢‘è½¨é“")
            clip.close()
        except Exception as e:
            print(f"âš ï¸  éŸ³é¢‘æå–å¤±è´¥: {str(e)}")
    
    # è½¬æ¢å…¶ä»–æ ¼å¼åˆ°MP4
    if need_convert:
        video_success, audio_path = convert_video_format(source_video_path, str(target_mp4))
        if not video_success:
            print(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {source_video_path}")
            return False
    
    # æ£€æŸ¥æœ€ç»ˆæ–‡ä»¶
    video_exists = target_mp4.exists() and target_mp4.stat().st_size > 0
    audio_exists = target_audio.exists() and target_audio.stat().st_size > 0
    
    print(f"ğŸ“‹ è§†é¢‘æ–‡ä»¶: {'âœ…' if video_exists else 'âŒ'} {target_mp4}")
    print(f"ğŸµ éŸ³é¢‘æ–‡ä»¶: {'âœ…' if audio_exists else 'âŒ'} {target_audio}")
    
    return video_exists

def convert_vhap_to_lam(vhap_dir, output_dir, max_frames=264, target_name="custom_drive", source_video_path=None):
    """
    è½¬æ¢VHAPè¾“å‡ºä¸ºLAMæ ¼å¼
    
    Args:
        vhap_dir: VHAPè¾“å‡ºç›®å½•è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„  
        max_frames: æœ€å¤§å¸§æ•°ï¼ˆé»˜è®¤264å¸§ï¼‰
        target_name: ç›®æ ‡é©±åŠ¨åç§°
        source_video_path: æºè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    vhap_path = Path(vhap_dir)
    output_path = Path(output_dir) / target_name
    output_path.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ”„ è½¬æ¢VHAPæ•°æ®ï¼š{vhap_path} -> {output_path}")
    
    # 1. å¤åˆ¶å¹¶è½¬æ¢flame_paramæ–‡ä»¶
    flame_param_dir = output_path / "flame_param"
    flame_param_dir.mkdir(exist_ok=True)
    
    vhap_flame_dir = vhap_path / "flame_param"
    flame_files = sorted([f for f in os.listdir(vhap_flame_dir) if f.endswith('.npz')])
    
    # é™åˆ¶æœ€å¤§å¸§æ•°
    flame_files = flame_files[:max_frames]
    print(f"ğŸ”¥ å¤„ç†{len(flame_files)}ä¸ªFLAMEå‚æ•°æ–‡ä»¶...")
    
    for i, flame_file in enumerate(flame_files):
        # è¯»å–VHAPæ ¼å¼
        vhap_data = np.load(vhap_flame_dir / flame_file)
        
        # è½¬æ¢ä¸ºLAMæ ¼å¼
        lam_data = {}
        
        # ç›´æ¥å¤åˆ¶çš„å‚æ•°
        for key in ['translation', 'rotation', 'neck_pose', 'jaw_pose', 'eyes_pose', 'expr']:
            if key in vhap_data:
                lam_data[key] = vhap_data[key]
        
        # è½¬æ¢shapeä¸ºbetasï¼ˆåªåœ¨ç¬¬ä¸€å¸§ä¿å­˜ï¼‰
        if i == 0 and 'shape' in vhap_data:
            # å°†(300,) -> (1, 300)
            lam_data['betas'] = vhap_data['shape'].reshape(1, -1)
        
        # ä¿å­˜è½¬æ¢åçš„æ–‡ä»¶
        output_file = flame_param_dir / f"{i:05d}.npz"
        np.savez(output_file, **lam_data)
    
    # 2. å¤åˆ¶canonical_flame_param.npz
    canonical_src = vhap_path / "canonical_flame_param.npz"
    canonical_dst = output_path / "canonical_flame_param.npz"
    if canonical_src.exists():
        shutil.copy2(canonical_src, canonical_dst)
        print("ğŸ“‹ å¤åˆ¶canonical_flame_param.npz")
    
    # 3. å¤åˆ¶transformsç›¸å…³æ–‡ä»¶
    for transform_file in ['transforms.json', 'transforms_train.json', 'transforms_test.json', 'transforms_val.json']:
        src_file = vhap_path / transform_file
        dst_file = output_path / transform_file
        if src_file.exists():
            shutil.copy2(src_file, dst_file)
            print(f"ğŸ“‹ å¤åˆ¶{transform_file}")
    
    # 4. åˆ›å»ºflame_params.jsonï¼ˆåˆå¹¶æ‰€æœ‰å¸§çš„å‚æ•°ï¼‰
    print("ğŸ“ ç”Ÿæˆflame_params.json...")
    create_flame_params_json(flame_param_dir, output_path, max_frames)
    
    # 5. å¤„ç†è§†é¢‘æ–‡ä»¶ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
    if source_video_path:
        print(f"\nğŸ¬ å¤„ç†è§†é¢‘æ–‡ä»¶...")
        video_success = process_video_file(source_video_path, output_path, target_name)
        if video_success:
            print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ")
        else:
            print(f"âš ï¸  è§†é¢‘å¤„ç†å¤±è´¥ï¼Œæ‚¨éœ€è¦æ‰‹åŠ¨æ·»åŠ è§†é¢‘æ–‡ä»¶")
    else:
        print(f"\nâš ï¸  æœªæä¾›è§†é¢‘è·¯å¾„ï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ ä»¥ä¸‹æ–‡ä»¶ï¼š")
        print(f"   - {target_name}.mp4 (é©±åŠ¨è§†é¢‘)")
        print(f"   - {target_name}.wav (éŸ³é¢‘æ–‡ä»¶)")
    
    # 6. æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
    print(f"\nğŸ“‹ æœ€ç»ˆæ–‡ä»¶æ£€æŸ¥:")
    required_files = [
        (output_path / f"{target_name}.mp4", "é©±åŠ¨è§†é¢‘"),
        (output_path / f"{target_name}.wav", "éŸ³é¢‘æ–‡ä»¶"),
        (output_path / "flame_param", "FLAMEå‚æ•°ç›®å½•"),
        (output_path / "flame_params.json", "åˆå¹¶çš„FLAMEå‚æ•°"),
        (output_path / "transforms.json", "å˜æ¢çŸ©é˜µ")
    ]
    
    all_ready = True
    for file_path, description in required_files:
        exists = file_path.exists()
        status = "âœ…" if exists else "âŒ"
        print(f"   {status} {description}: {file_path}")
        if not exists:
            all_ready = False
    
    if all_ready:
        print(f"\nğŸ‰ è½¬æ¢å®Œæˆï¼æ‰€æœ‰å¿…éœ€æ–‡ä»¶å·²å°±ç»ªï¼Œå¯ç›´æ¥åœ¨multi_view_image_generation.pyä¸­ä½¿ç”¨")
        print(f"   é©±åŠ¨åç§°è®¾ç½®ä¸º: drive_name = '{target_name}'")
    else:
        print(f"\nâš ï¸  è½¬æ¢å®Œæˆï¼Œä½†éƒ¨åˆ†æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ‰‹åŠ¨è¡¥é½åä½¿ç”¨")
    
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{output_path}")

def create_flame_params_json(flame_param_dir, output_dir, max_frames):
    """åˆ›å»ºåˆå¹¶çš„flame_params.jsonæ–‡ä»¶"""
    
    all_params = {
        "expr": [],
        "rotation": [], 
        "neck_pose": [],
        "jaw_pose": [],
        "eyes_pose": [],
        "translation": [],
        "betas": None
    }
    
    # è¯»å–æ‰€æœ‰å¸§çš„å‚æ•°
    for i in range(max_frames):
        flame_file = flame_param_dir / f"{i:05d}.npz"
        if flame_file.exists():
            data = np.load(flame_file)
            
            for key in ['expr', 'rotation', 'neck_pose', 'jaw_pose', 'eyes_pose', 'translation']:
                if key in data:
                    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
                    if data[key].ndim == 2:
                        all_params[key].append(data[key][0].tolist())
                    else:
                        all_params[key].append(data[key].tolist())
            
            # betasåªä¿å­˜ä¸€æ¬¡
            if all_params["betas"] is None and "betas" in data:
                all_params["betas"] = data["betas"][0].tolist()
    
    # ä¿å­˜JSONæ–‡ä»¶
    json_file = output_dir / "flame_params.json"
    with open(json_file, 'w') as f:
        json.dump(all_params, f, indent=2)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='è½¬æ¢VHAPè¾“å‡ºä¸ºLAMå…¼å®¹æ ¼å¼')
    parser.add_argument('--vhap_dir', type=str, 
                       default="/root/autodl-tmp/VHAP_track/mono_jp/export_epoch0",
                       help='VHAPè¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str,
                       default="/root/autodl-tmp/LAM/assets/sample_motion/export", 
                       help='LAMè¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--target_name', type=str, default="custom_jp_drive",
                       help='ç›®æ ‡é©±åŠ¨åç§°')
    parser.add_argument('--max_frames', type=int, default=264,
                       help='æœ€å¤§å¸§æ•°')
    parser.add_argument('--source_video_path', type=str,
                       default="/root/autodl-tmp/datasets/mono_jp/apple_jp_3.mov",
                       help='æºè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ.mp4/.mov/.avi/.mkvç­‰æ ¼å¼ï¼‰')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ å¼€å§‹è½¬æ¢VHAPæ•°æ®...")
    print(f"   VHAPç›®å½•: {args.vhap_dir}")
    print(f"   è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"   ç›®æ ‡åç§°: {args.target_name}")
    print(f"   æœ€å¤§å¸§æ•°: {args.max_frames}")
    print(f"   æºè§†é¢‘è·¯å¾„: {args.source_video_path}")
    
    convert_vhap_to_lam(
        vhap_dir=args.vhap_dir,
        output_dir=args.output_dir,
        max_frames=args.max_frames,
        target_name=args.target_name,
        source_video_path=args.source_video_path
    ) 